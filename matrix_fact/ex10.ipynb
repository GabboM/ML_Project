{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "Note that `ratings` is a sparse matrix that in the shape of (num_items, num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 3179, number of users: 494\n"
     ]
    }
   ],
   "source": [
    "from helpers import load_data, preprocess_data\n",
    "\n",
    "path_dataset = \"../output/score_matrix.csv\"\n",
    "ratings = load_data(path_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1.0000529813451506, 1.0035518191997495, 1.0004785611262843, 1.0001074120481983, 1.0000276958872725, 1.000046543637069, 1.0000694276768718, 1.000064531800633, 1.0001675553127685, 1.000029510225063, 1.0001903995858366, 1.000254706450695, 1.0000584469491842, 1.0000631664671524, 1.0000258493553629, 1.0001709742661231, 1.000192587666512, 1.0001021726620587, 1.0000186549990426, 1.0001473039932045, 1.0000484211152405, 1.000089600040033]),\n",
       "       list([1.0000086478811678]), list([1.0000162479096564]), ...,\n",
       "       list([1.2736950172324004]), list([1.1598356692131497]),\n",
       "       list([1.0000016669781])], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the number of ratings per movie and user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min # of items per user = 1, min # of users per item = 1.\n"
     ]
    }
   ],
   "source": [
    "from plots import plot_raw_data\n",
    "\n",
    "num_items_per_user, num_users_per_item = plot_raw_data(ratings)\n",
    "\n",
    "print(\"min # of items per user = {}, min # of users per item = {}.\".format(\n",
    "        min(num_items_per_user), min(num_users_per_item)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into a train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(ratings, num_items_per_user, num_users_per_item,\n",
    "               min_num_ratings, p_test=0.1):\n",
    "    \"\"\"split the ratings to training data and test data.\n",
    "    Args:\n",
    "        min_num_ratings: \n",
    "            all users and items we keep must have at least min_num_ratings per user and per item. \n",
    "    \"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "    \n",
    "    # select user and item based on the condition.\n",
    "    valid_users = np.where(num_items_per_user >= min_num_ratings)[0]\n",
    "    valid_items = np.where(num_users_per_item >= min_num_ratings)[0]\n",
    "    valid_ratings = ratings[valid_items, :][: , valid_users]  \n",
    "    \n",
    "    # init\n",
    "    num_rows, num_cols = valid_ratings.shape\n",
    "    train = sp.lil_matrix((num_rows, num_cols))\n",
    "    test = sp.lil_matrix((num_rows, num_cols))\n",
    "    print(valid_ratings.shape, train.shape)\n",
    "    \n",
    "    print(\"the shape of original ratings. (# of row, # of col): {}\".format(\n",
    "        ratings.shape))\n",
    "    print(\"the shape of valid ratings. (# of row, # of col): {}\".format(\n",
    "        (num_rows, num_cols)))\n",
    "\n",
    "    nz_items, nz_users = valid_ratings.nonzero()\n",
    "    print(nz_items, nz_users)\n",
    "    \n",
    "    # split the data\n",
    "    for user in set(nz_users):\n",
    "        # randomly select a subset of ratings\n",
    "        row, col = valid_ratings[:, user].nonzero()\n",
    "        selects = np.random.choice(row, size=int(len(row) * p_test))\n",
    "        residual = list(set(row) - set(selects))\n",
    "        print(\"User:\", user, \"Select:\", selects, \"Res:\", residual)\n",
    "        print(valid_ratings[residual, user])\n",
    "        print(train[residual, user])\n",
    "        # add to train set\n",
    "        train[residual, user] = valid_ratings[residual, user]\n",
    "\n",
    "        # add to test set\n",
    "        test[selects, user] = valid_ratings[selects, user]\n",
    "\n",
    "    print(\"Total number of nonzero elements in origial data:{v}\".format(v=ratings.nnz))\n",
    "    print(\"Total number of nonzero elements in train data:{v}\".format(v=train.nnz))\n",
    "    print(\"Total number of nonzero elements in test data:{v}\".format(v=test.nnz))\n",
    "    return valid_ratings, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3179, 494) (3179, 494)\n",
      "the shape of original ratings. (# of row, # of col): (3179, 494)\n",
      "the shape of valid ratings. (# of row, # of col): (3179, 494)\n",
      "[   0    0    0 ... 3176 3177 3178] [  5   9  39 ... 394 394 394]\n",
      "User: 0 Select: [1905 1832   86  673 1919] Res: [641, 514, 643, 4, 2055, 1554, 2073, 538, 29, 286, 1310, 160, 34, 1831, 682, 48, 688, 1205, 54, 2488, 829, 1853, 2371, 69, 1866, 2124, 77, 1998, 81, 849, 342, 1879, 2520, 2266, 2521, 2783, 2027, 1391, 880, 1008, 115, 116, 885, 630, 633, 1915, 252, 1278]\n",
      "  (0, 0)\t1.006555089333367\n",
      "  (1, 0)\t1.0000104920571196\n",
      "  (2, 0)\t1.0270059801359777\n",
      "  (3, 0)\t1.2737422056114909\n",
      "  (4, 0)\t1.0016454558042955\n",
      "  (5, 0)\t1.3772773039148354\n",
      "  (6, 0)\t1.0000044014711689\n",
      "  (7, 0)\t1.0005198396067654\n",
      "  (8, 0)\t1.2367166056899657\n",
      "  (9, 0)\t1.0052036619152964\n",
      "  (10, 0)\t1.0099717002813073\n",
      "  (11, 0)\t1.0580143413697234\n",
      "  (12, 0)\t1.0032683034490648\n",
      "  (13, 0)\t1.0000110171033147\n",
      "  (14, 0)\t1.0737120824698003\n",
      "  (15, 0)\t1.052151983758707\n",
      "  (16, 0)\t1.0013493319148237\n",
      "  (17, 0)\t1.0006440874482865\n",
      "  (18, 0)\t1.1377758049991256\n",
      "  (19, 0)\t1.0000004099871462\n",
      "  (20, 0)\t1.0403187634496196\n",
      "  (21, 0)\t1.0012132139093064\n",
      "  (22, 0)\t1.0005441856328838\n",
      "  (23, 0)\t1.2607076275928506\n",
      "  (24, 0)\t1.0175609587052434\n",
      "  (25, 0)\t1.0265775658312377\n",
      "  (26, 0)\t1.000673869774305\n",
      "  (27, 0)\t1.00041317145668\n",
      "  (28, 0)\t1.0010487430896242\n",
      "  (29, 0)\t1.0029296336027584\n",
      "  (30, 0)\t1.0408299575716164\n",
      "  (31, 0)\t1.0001351289555174\n",
      "  (32, 0)\t1.0000044014711689\n",
      "  (33, 0)\t1.0000523623392352\n",
      "  (34, 0)\t1.0000044014711689\n",
      "  (35, 0)\t1.0344002720475813\n",
      "  (36, 0)\t1.0006977156268468\n",
      "  (37, 0)\t1.1047955326902295\n",
      "  (38, 0)\t1.0010338329642865\n",
      "  (39, 0)\t1.0004502744267694\n",
      "  (40, 0)\t1.9023777394927204\n",
      "  (41, 0)\t1.0736707128314218\n",
      "  (42, 0)\t1.1369909527723991\n",
      "  (43, 0)\t2.573722607526633\n",
      "  (44, 0)\t1.6164572221919093\n",
      "  (45, 0)\t1.3550249293798915\n",
      "  (46, 0)\t1.4926789518252082\n",
      "  (47, 0)\t1.000009159332846\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shape mismatch in assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-7321a8796f4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m valid_ratings, train, test = split_data(\n\u001b[1;32m----> 4\u001b[1;33m     ratings, num_items_per_user, num_users_per_item, min_num_ratings=1, p_test=0.1)\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplot_train_test_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-53-20131a39b556>\u001b[0m in \u001b[0;36msplit_data\u001b[1;34m(ratings, num_items_per_user, num_users_per_item, min_num_ratings, p_test)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mresidual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;31m# add to train set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mresidual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mratings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mresidual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;31m# add to test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\sparse\\lil.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, x)\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_intXint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[1;31m# Everything else takes the normal path.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m         \u001b[0mIndexMixin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_mul_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\sparse\\_index.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, x)\u001b[0m\n\u001b[0;32m    111\u001b[0m             if not ((broadcast_row or x.shape[0] == i.shape[0]) and\n\u001b[0;32m    112\u001b[0m                     (broadcast_col or x.shape[1] == i.shape[1])):\n\u001b[1;32m--> 113\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'shape mismatch in assignment'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shape mismatch in assignment"
     ]
    }
   ],
   "source": [
    "from plots import plot_train_test_data\n",
    "\n",
    "valid_ratings, train, test = split_data(\n",
    "    ratings, num_items_per_user, num_users_per_item, min_num_ratings=1, p_test=0.1)\n",
    "plot_train_test_data(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Baselines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the global mean to do the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test RMSE of baseline using the global mean: [[1.12312029]].\n"
     ]
    }
   ],
   "source": [
    "from helpers import calculate_mse\n",
    "\n",
    "def baseline_global_mean(train, test):\n",
    "    \"\"\"baseline method: use the global mean.\"\"\"\n",
    "    # find the non zero ratings in the train\n",
    "    nonzero_train = train[train.nonzero()]\n",
    "\n",
    "    # calculate the global mean\n",
    "    global_mean_train = nonzero_train.mean()\n",
    "\n",
    "    # find the non zero ratings in the test\n",
    "    nonzero_test = test[test.nonzero()].todense()\n",
    "\n",
    "    # predict the ratings as global mean\n",
    "    mse = calculate_mse(nonzero_test, global_mean_train)\n",
    "    rmse = np.sqrt(1.0 * mse / nonzero_test.shape[1])\n",
    "    print(\"test RMSE of baseline using the global mean: {v}.\".format(v=rmse))\n",
    "\n",
    "baseline_global_mean(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the user means as the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test RMSE of the baseline using the user mean: [[1.05519755]].\n"
     ]
    }
   ],
   "source": [
    "def baseline_user_mean(train, test):\n",
    "    \"\"\"baseline method: use the user means as the prediction.\"\"\"\n",
    "    mse = 0\n",
    "    num_items, num_users = train.shape\n",
    "\n",
    "    for user_index in range(num_users):\n",
    "        # find the non-zero ratings for each user in the training dataset\n",
    "        train_ratings = train[:, user_index]\n",
    "        nonzeros_train_ratings = train_ratings[train_ratings.nonzero()]\n",
    "        \n",
    "        # calculate the mean if the number of elements is not 0\n",
    "        if nonzeros_train_ratings.shape[0] != 0:\n",
    "            user_train_mean = nonzeros_train_ratings.mean()\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        # find the non-zero ratings for each user in the test dataset\n",
    "        test_ratings = test[:, user_index]\n",
    "        nonzeros_test_ratings = test_ratings[test_ratings.nonzero()].todense()\n",
    "        \n",
    "        # calculate the test error \n",
    "        mse += calculate_mse(nonzeros_test_ratings, user_train_mean)\n",
    "    rmse = np.sqrt(1.0 * mse / test.nnz)\n",
    "    print(\"test RMSE of the baseline using the user mean: {v}.\".format(v=rmse))\n",
    "\n",
    "baseline_user_mean(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the item means as the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test RMSE of the baseline using the item mean: [[1.02586333]].\n"
     ]
    }
   ],
   "source": [
    "def baseline_item_mean(train, test):\n",
    "    \"\"\"baseline method: use item means as the prediction.\"\"\"\n",
    "    mse = 0\n",
    "    num_items, num_users = train.shape\n",
    "    \n",
    "    for item_index in range(num_items):\n",
    "        # find the non-zero ratings for each item in the training dataset\n",
    "        train_ratings = train[item_index, :]\n",
    "        nonzeros_train_ratings = train_ratings[train_ratings.nonzero()]\n",
    "\n",
    "        # calculate the mean if the number of elements is not 0\n",
    "        if nonzeros_train_ratings.shape[0] != 0:\n",
    "            item_train_mean = nonzeros_train_ratings.mean()\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        # find the non-zero ratings for each movie in the test dataset\n",
    "        test_ratings = test[item_index, :]\n",
    "        nonzeros_test_ratings = test_ratings[test_ratings.nonzero()].todense()\n",
    "        \n",
    "        # calculate the test error \n",
    "        mse += calculate_mse(nonzeros_test_ratings, item_train_mean)\n",
    "    rmse = np.sqrt(1.0 * mse / test.nnz)\n",
    "    print(\"test RMSE of the baseline using the item mean: {v}.\".format(v=rmse))\n",
    "    \n",
    "baseline_item_mean(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn the Matrix Factorization using SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_MF(train, num_features):\n",
    "    \"\"\"init the parameter for matrix factorization.\"\"\"\n",
    "        \n",
    "    num_item, num_user = train.get_shape()\n",
    "\n",
    "    user_features = np.random.rand(num_features, num_user)\n",
    "    item_features = np.random.rand(num_features, num_item)\n",
    "\n",
    "    # start by item features.\n",
    "    item_nnz = train.getnnz(axis=1)\n",
    "    item_sum = train.sum(axis=1)\n",
    "\n",
    "    for ind in range(num_item):\n",
    "        item_features[0, ind] = item_sum[ind, 0] / item_nnz[ind]\n",
    "    return user_features, item_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the cost by the method of matrix factorization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error(data, user_features, item_features, nz):\n",
    "    \"\"\"compute the loss (MSE) of the prediction of nonzero elements.\"\"\"\n",
    "    mse = 0\n",
    "    for row, col in nz:\n",
    "        item_info = item_features[:, row]\n",
    "        user_info = user_features[:, col]\n",
    "        mse += (data[row, col] - user_info.T.dot(item_info)) ** 2\n",
    "    return np.sqrt(1.0 * mse / len(nz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learn the matrix factorization using SGD...\n",
      "iter: 0, RMSE on training set: 1.0794580554414712.\n",
      "iter: 1, RMSE on training set: 1.0319645729023519.\n",
      "iter: 2, RMSE on training set: 1.0031417606873387.\n",
      "iter: 3, RMSE on training set: 0.9838915467154317.\n",
      "iter: 4, RMSE on training set: 0.9760855163496233.\n",
      "iter: 5, RMSE on training set: 0.9711375257842211.\n",
      "iter: 6, RMSE on training set: 0.96713071614336.\n",
      "iter: 7, RMSE on training set: 0.9630523850421808.\n",
      "iter: 8, RMSE on training set: 0.9600590986751028.\n",
      "iter: 9, RMSE on training set: 0.9597659747827576.\n",
      "iter: 10, RMSE on training set: 0.9578435018152335.\n",
      "iter: 11, RMSE on training set: 0.9580422789086744.\n",
      "iter: 12, RMSE on training set: 0.9569928922921364.\n",
      "iter: 13, RMSE on training set: 0.9567559504480108.\n",
      "iter: 14, RMSE on training set: 0.9565716010445127.\n",
      "iter: 15, RMSE on training set: 0.9564573187824981.\n",
      "iter: 16, RMSE on training set: 0.9560851742908765.\n",
      "iter: 17, RMSE on training set: 0.9558197932325914.\n",
      "iter: 18, RMSE on training set: 0.9556006841488749.\n",
      "iter: 19, RMSE on training set: 0.9554492886288611.\n",
      "RMSE on test data: 0.9933528979610673.\n"
     ]
    }
   ],
   "source": [
    "def matrix_factorization_SGD(train, test):\n",
    "    \"\"\"matrix factorization by SGD.\"\"\"\n",
    "    # define parameters\n",
    "    gamma = 0.01\n",
    "    num_features = 20   # K in the lecture notes\n",
    "    lambda_user = 0.1\n",
    "    lambda_item = 0.7\n",
    "    num_epochs = 20     # number of full passes through the train set\n",
    "    errors = [0]\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init matrix\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    # find the non-zero ratings indices \n",
    "    nz_row, nz_col = train.nonzero()\n",
    "    nz_train = list(zip(nz_row, nz_col))\n",
    "    nz_row, nz_col = test.nonzero()\n",
    "    nz_test = list(zip(nz_row, nz_col))\n",
    "\n",
    "    print(\"learn the matrix factorization using SGD...\")\n",
    "    for it in range(num_epochs):        \n",
    "        # shuffle the training rating indices\n",
    "        np.random.shuffle(nz_train)\n",
    "        \n",
    "        # decrease step size\n",
    "        gamma /= 1.2\n",
    "        \n",
    "        for d, n in nz_train:\n",
    "            # update W_d (item_features[:, d]) and Z_n (user_features[:, n])\n",
    "            item_info = item_features[:, d]\n",
    "            user_info = user_features[:, n]\n",
    "            err = train[d, n] - user_info.T.dot(item_info)\n",
    "    \n",
    "            # calculate the gradient and update\n",
    "            item_features[:, d] += gamma * (err * user_info - lambda_item * item_info)\n",
    "            user_features[:, n] += gamma * (err * item_info - lambda_user * user_info)\n",
    "\n",
    "        rmse = compute_error(train, user_features, item_features, nz_train)\n",
    "        print(\"iter: {}, RMSE on training set: {}.\".format(it, rmse))\n",
    "        \n",
    "        errors.append(rmse)\n",
    "\n",
    "    # evaluate the test error\n",
    "    rmse = compute_error(test, user_features, item_features, nz_test)\n",
    "    print(\"RMSE on test data: {}.\".format(rmse))\n",
    "\n",
    "matrix_factorization_SGD(train, test)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn the Matrix Factorization using Alternating Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_user_feature(\n",
    "        train, item_features, lambda_user,\n",
    "        nnz_items_per_user, nz_user_itemindices):\n",
    "    \"\"\"update user feature matrix.\"\"\"\n",
    "    \"\"\"the best lambda is assumed to be nnz_items_per_user[user] * lambda_user\"\"\"\n",
    "    num_user = nnz_items_per_user.shape[0]\n",
    "    num_feature = item_features.shape[0]\n",
    "    lambda_I = lambda_user * sp.eye(num_feature)\n",
    "    updated_user_features = np.zeros((num_feature, num_user))\n",
    "\n",
    "    for user, items in nz_user_itemindices:\n",
    "        # extract the columns corresponding to the prediction for given item\n",
    "        M = item_features[:, items]\n",
    "        \n",
    "        # update column row of user features\n",
    "        V = M @ train[items, user]\n",
    "        A = M @ M.T + nnz_items_per_user[user] * lambda_I\n",
    "        X = np.linalg.solve(A, V)\n",
    "        updated_user_features[:, user] = np.copy(X.T)\n",
    "    return updated_user_features\n",
    "\n",
    "def update_item_feature(\n",
    "        train, user_features, lambda_item,\n",
    "        nnz_users_per_item, nz_item_userindices):\n",
    "    \"\"\"update item feature matrix.\"\"\"\n",
    "    \"\"\"the best lambda is assumed to be nnz_items_per_item[item] * lambda_item\"\"\"\n",
    "    num_item = nnz_users_per_item.shape[0]\n",
    "    num_feature = user_features.shape[0]\n",
    "    lambda_I = lambda_item * sp.eye(num_feature)\n",
    "    updated_item_features = np.zeros((num_feature, num_item))\n",
    "\n",
    "    for item, users in nz_item_userindices:\n",
    "        # extract the columns corresponding to the prediction for given user\n",
    "        M = user_features[:, users]\n",
    "        V = M @ train[item, users].T\n",
    "        A = M @ M.T + nnz_users_per_item[item] * lambda_I\n",
    "        X = np.linalg.solve(A, V)\n",
    "        updated_item_features[:, item] = np.copy(X.T)\n",
    "    return updated_item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "start the ALS algorithm...\n",
      "RMSE on training set: 1.9143121183599194.\n",
      "RMSE on training set: 1.1622022253731712.\n",
      "RMSE on training set: 1.0420133287908302.\n",
      "RMSE on training set: 0.9933967926816162.\n",
      "RMSE on training set: 0.9692786660287611.\n",
      "RMSE on training set: 0.9558532754192863.\n",
      "RMSE on training set: 0.9477648064480156.\n",
      "RMSE on training set: 0.9426118429974033.\n",
      "RMSE on training set: 0.93919778333181.\n",
      "RMSE on training set: 0.9368731659152135.\n",
      "RMSE on training set: 0.9352600567774367.\n",
      "RMSE on training set: 0.9341259243082286.\n",
      "RMSE on training set: 0.9333213428535561.\n",
      "RMSE on training set: 0.9327470608663175.\n",
      "RMSE on training set: 0.932335505867805.\n",
      "RMSE on training set: 0.9320398307964032.\n",
      "RMSE on training set: 0.9318271257549207.\n",
      "RMSE on training set: 0.9316740503176432.\n",
      "RMSE on training set: 0.9315639373746272.\n",
      "RMSE on training set: 0.9314848270110108.\n",
      "test RMSE after running ALS: 0.9674977952556412.\n"
     ]
    }
   ],
   "source": [
    "from helpers import build_index_groups\n",
    "\n",
    "\n",
    "def ALS(train, test):\n",
    "    \"\"\"Alternating Least Squares (ALS) algorithm.\"\"\"\n",
    "    # define parameters\n",
    "    num_features = 20   # K in the lecture notes\n",
    "    lambda_user = 0.1\n",
    "    lambda_item = 0.7\n",
    "    stop_criterion = 1e-4\n",
    "    change = 1\n",
    "    error_list = [0, 0]\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init ALS\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    # get the number of non-zero ratings for each user and item\n",
    "    nnz_items_per_user, nnz_users_per_item = train.getnnz(axis=0), train.getnnz(axis=1)\n",
    "    \n",
    "    # group the indices by row or column index\n",
    "    nz_train, nz_item_userindices, nz_user_itemindices = build_index_groups(train)\n",
    "\n",
    "    # run ALS\n",
    "    print(\"\\nstart the ALS algorithm...\")\n",
    "    while change > stop_criterion:\n",
    "        # update user feature & item feature\n",
    "        user_features = update_user_feature(\n",
    "            train, item_features, lambda_user,\n",
    "            nnz_items_per_user, nz_user_itemindices)\n",
    "        item_features = update_item_feature(\n",
    "            train, user_features, lambda_item,\n",
    "            nnz_users_per_item, nz_item_userindices)\n",
    "\n",
    "        error = compute_error(train, user_features, item_features, nz_train)\n",
    "        print(\"RMSE on training set: {}.\".format(error))\n",
    "        error_list.append(error)\n",
    "        change = np.fabs(error_list[-1] - error_list[-2])\n",
    "\n",
    "    # evaluate the test error\n",
    "    nnz_row, nnz_col = test.nonzero()\n",
    "    nnz_test = list(zip(nnz_row, nnz_col))\n",
    "    rmse = compute_error(test, user_features, item_features, nnz_test)\n",
    "    print(\"test RMSE after running ALS: {v}.\".format(v=rmse))\n",
    "\n",
    "ALS(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
